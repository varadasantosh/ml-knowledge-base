{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1636039a-1723-401d-9155-286a9c1254ac",
   "metadata": {},
   "source": [
    "# Install NVCC For Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b470ae4-a784-4781-bb05-aaf995850bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvcc4jupyter in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nvcc4jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c488f6-d44f-49c1-b168-965effef933d",
   "metadata": {},
   "source": [
    "# Load the NVCC Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b646724-82ab-40af-a580-ef589a1095b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source files will be saved in \"/tmp/tmp9pqtvywp\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59d65a-240d-4dc8-93f8-a254b11dd2ed",
   "metadata": {},
   "source": [
    "# Matrix Multipliation with 1D Grid & 1D Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0974a11a-c7e1-4198-a9e9-0026396f0709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMM Started\n",
      "GEMM Completed Successfully\n",
      "1120    1148    1176    1204    1232    1260    1288    1316    \n",
      "2912    3004    3096    3188    3280    3372    3464    3556    \n",
      "4704    4860    5016    5172    5328    5484    5640    5796    \n",
      "6496    6716    6936    7156    7376    7596    7816    8036    \n",
      "8288    8572    8856    9140    9424    9708    9992    10276    \n",
      "10080    10428    10776    11124    11472    11820    12168    12516    \n",
      "11872    12284    12696    13108    13520    13932    14344    14756    \n",
      "13664    14140    14616    15092    15568    16044    16520    16996    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define N 8\n",
    "\n",
    "__global__ void gemm(int* dA, int* dB, int* dC, int mat_dim)\n",
    "{\n",
    "\n",
    "        int threadId = (blockIdx.x*blockDim.x) +threadIdx.x;\n",
    "\n",
    "        int sum= 0;\n",
    "        int row  = threadId/mat_dim;\n",
    "        int col  = threadId%mat_dim; \n",
    "\n",
    "        if (row < N && col < N)\n",
    "        {\n",
    "            for (int k=0 ; k<mat_dim; k++)\n",
    "            {\n",
    "              sum = sum + (dA[(row*mat_dim)+k] * dB[(k*mat_dim)+col]);\n",
    "             }\n",
    "           dC[threadId] = sum;\n",
    "        }\n",
    "\n",
    "}\n",
    "\n",
    "__host__ int main(){\n",
    "\n",
    "   printf(\"GEMM Started\\n\");     \n",
    "   int* A;\n",
    "   int* B;\n",
    "   int* C;\n",
    "\n",
    "   int* dA;\n",
    "   int* dB;\n",
    "   int* dC;\n",
    "\n",
    "   A = (int*) malloc(N*N*sizeof(int));\n",
    "   B = (int*) malloc(N*N*sizeof(int));\n",
    "   C = (int*) malloc(N*N*sizeof(int));\n",
    "\n",
    "  cudaMalloc((void**)&dA, N*N * sizeof(int));\n",
    "  cudaMalloc((void**)&dB, N*N * sizeof(int));\n",
    "  cudaMalloc((void**)&dC, N*N * sizeof(int));\n",
    "\n",
    "   for (int i=0; i<N; i++) \n",
    "   {\n",
    "       for (int j=0; j<N; j++) \n",
    "       {\n",
    "           A[i*N+j] = i*N+j;\n",
    "           B[i*N+j] = i*N+j;\n",
    "        }\n",
    "   } \n",
    "\n",
    "   cudaMemcpy(dA, A, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "   cudaMemcpy(dB, B, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "   \n",
    "   gemm<<<1,N*N>>>(dA,dB,dC,N);\n",
    "\n",
    "   cudaDeviceSynchronize();\n",
    "\n",
    "   cudaError_t err = cudaGetLastError();\n",
    "    if (err != cudaSuccess) {\n",
    "        printf(\"Kernel Launch Failed: %s\\n\", cudaGetErrorString(err));\n",
    "    } \n",
    "   printf(\"GEMM Completed Successfully\\n\");\n",
    "\n",
    "   cudaMemcpy(C,dC, N*N*sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    for (int i=0; i<N; i++)\n",
    "  {\n",
    "      for (int j=0; j<N; j++)\n",
    "    {\n",
    "        printf(\"%u    \",C[i*N+j]);\n",
    "    }\n",
    "     printf(\"\\n\");\n",
    "   }\n",
    "\n",
    "   cudaFree(dA);\n",
    "   cudaFree(dB);\n",
    "   cudaFree(dC);\n",
    "   \n",
    "   free(A);\n",
    "   free(B);\n",
    "   free(C);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea791eb-8de4-4a25-94aa-67b1d29800bd",
   "metadata": {},
   "source": [
    "# Matrix Multiplications using using 2D Grid & 2D Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835270c8-a145-4084-b64c-deec0e1fa8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120 1148 1176 1204 1232 1260 1288 1316 \n",
      "2912 3004 3096 3188 3280 3372 3464 3556 \n",
      "4704 4860 5016 5172 5328 5484 5640 5796 \n",
      "6496 6716 6936 7156 7376 7596 7816 8036 \n",
      "8288 8572 8856 9140 9424 9708 9992 10276 \n",
      "10080 10428 10776 11124 11472 11820 12168 12516 \n",
      "11872 12284 12696 13108 13520 13932 14344 14756 \n",
      "13664 14140 14616 15092 15568 16044 16520 16996 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <stdio.h>\n",
    "#define N 8\n",
    "\n",
    "__global__ void gemm(int* dA, int* dB, int* dC, int matDim){\n",
    "\n",
    "    \n",
    "    int row = blockIdx.y*blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    int sum =0;\n",
    "\n",
    "    if(row<N && col<N)\n",
    "    {\n",
    "        for (int k=0;k<N;k++){\n",
    "    \n",
    "            sum = sum + dA[row*N+k] * dB[k*N+col]; \n",
    "        \n",
    "        }  \n",
    "    \n",
    "         dC[row*N+col] = sum;\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "__host__ int main(){\n",
    "\n",
    "\n",
    "    int *A, *B, *C;\n",
    "    int *dA, *dB, *dC;\n",
    "\n",
    "    A = (int*) malloc(N*N*sizeof(int));\n",
    "    B = (int*) malloc(N*N*sizeof(int));\n",
    "    C = (int*) malloc(N*N*sizeof(int));\n",
    "\n",
    "    cudaMalloc( (void**)&dA, N*N*sizeof(int));\n",
    "    cudaMalloc( (void**)&dB, N*N*sizeof(int));\n",
    "    cudaMalloc( (void**)&dC, N*N*sizeof(int)); \n",
    "\n",
    "    for (int i=0; i<N; i++)\n",
    "   {\n",
    "     for (int j=0; j<N; j++ )\n",
    "     {\n",
    "        A[i*N+j] = i*N+j;\n",
    "        B[i*N+j] = i*N+j; \n",
    "          \n",
    "      }  \n",
    "    }\n",
    "\n",
    "    cudaMemcpy(dA, A, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dB, B, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    int block_size= 4;\n",
    "    dim3 blockDim(block_size,block_size);\n",
    "    dim3 gridDim((N+block_size-1)/block_size, (N+block_size-1)/block_size);\n",
    "    \n",
    "\n",
    "    gemm<<<gridDim,blockDim>>>(dA,dB,dC,N);\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaMemcpy(C,dC,N*N*sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "\n",
    "    for(int i=0; i<N; i++)\n",
    "    {\n",
    "      for(int j=0; j<N; j++)\n",
    "      {\n",
    "         printf(\"%u \", C[i*N+j]);\n",
    "      }\n",
    "       printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    cudaFree(dA);\n",
    "    cudaFree(dB);\n",
    "    cudaFree(dC);\n",
    "\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "    \n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a038d4-175b-44ab-98b0-7c42413e22e6",
   "metadata": {},
   "source": [
    "# Matrix Multiplications using using 1D Grid & 3D Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a138d5ba-01ed-4e27-9a48-696fe22df48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120 1148 1176 1204 1232 1260 1288 1316 \n",
      "2912 3004 3096 3188 3280 3372 3464 3556 \n",
      "4704 4860 5016 5172 5328 5484 5640 5796 \n",
      "6496 6716 6936 7156 7376 7596 7816 8036 \n",
      "8288 8572 8856 9140 9424 9708 9992 10276 \n",
      "10080 10428 10776 11124 11472 11820 12168 12516 \n",
      "11872 12284 12696 13108 13520 13932 14344 14756 \n",
      "13664 14140 14616 15092 15568 16044 16520 16996 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <stdio.h>\n",
    "#define N 8\n",
    "#define BLOCK_SIZE 4\n",
    "\n",
    "__global__ void gemm(int* dA, int* dB, int* dC, int matDim){\n",
    "\n",
    "    \n",
    "    int localThreadId =  threadIdx.z*blockDim.y*blockDim.x + threadIdx.y*blockDim.x+threadIdx.x;\n",
    "    int globalThreadId = (blockIdx.x * blockDim.x* blockDim.y * blockDim.z) + localThreadId; \n",
    "\n",
    "    int row  = globalThreadId/matDim;\n",
    "    int col  = globalThreadId%matDim;\n",
    "\n",
    "    int sum =0;\n",
    "\n",
    "    if(row<N && col<N)\n",
    "   {\n",
    "        for (int k=0;k<N;k++){\n",
    "    \n",
    "            sum = sum + dA[row*N+k] * dB[k*N+col]; \n",
    "        \n",
    "        }  \n",
    "    \n",
    "         dC[row*N+col] = sum;\n",
    "    } \n",
    "}\n",
    "\n",
    "\n",
    "__host__ int main(){\n",
    "\n",
    "\n",
    "    int *A, *B, *C;\n",
    "    int *dA, *dB, *dC;\n",
    "\n",
    "    A = (int*) malloc(N*N*sizeof(int));\n",
    "    B = (int*) malloc(N*N*sizeof(int));\n",
    "    C = (int*) malloc(N*N*sizeof(int));\n",
    "\n",
    "    cudaMalloc( (void**)&dA, N*N*sizeof(int));\n",
    "    cudaMalloc( (void**)&dB, N*N*sizeof(int));\n",
    "    cudaMalloc( (void**)&dC, N*N*sizeof(int)); \n",
    "\n",
    "    for (int i=0; i<N; i++)\n",
    "   {\n",
    "     for (int j=0; j<N; j++ )\n",
    "     {\n",
    "        A[i*N+j] = i*N+j;\n",
    "        B[i*N+j] = i*N+j; \n",
    "          \n",
    "      }  \n",
    "    }\n",
    "\n",
    "    cudaMemcpy(dA, A, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dB, B, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 blockDim(BLOCK_SIZE,BLOCK_SIZE,BLOCK_SIZE);\n",
    "    dim3 gridDim((N+BLOCK_SIZE-1)/BLOCK_SIZE);\n",
    "    \n",
    "\n",
    "    gemm<<<gridDim,blockDim>>>(dA,dB,dC,N);\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaMemcpy(C,dC,N*N*sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    for(int i=0; i<N; i++)\n",
    "    {\n",
    "      for(int j=0; j<N; j++)\n",
    "      {\n",
    "         printf(\"%u \", C[i*N+j]);\n",
    "      }\n",
    "       printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    cudaFree(dA);\n",
    "    cudaFree(dB);\n",
    "    cudaFree(dC);\n",
    "\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1cc9f3-9913-45f3-9ea6-ca3593a5a636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
